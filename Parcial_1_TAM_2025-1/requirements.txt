# ===  búsqueda inicial con ElasticNetCV ===
# Define el espacio de búsqueda inicial amplio
alphas_cv = np.logspace(-2, 2, 50)
ratios_cv = [0.1, 0.5, 0.7, 0.9, 0.95, 1.0]

# Entrenamiento con validación cruzada
start = time.time()

elastic_cv = ElasticNetCV(
    alphas=alphas_cv,
    l1_ratio=ratios_cv,
    cv=cv,
    n_jobs=-1,
    max_iter=10000,
    random_state=42
)

elastic_cv.fit(X_train_scaled, np.log1p(y_train))

end = time.time()
tiempo_cv = end - start

# Obtener mejores hiperparámetros
alpha_opt = elastic_cv.alpha_
l1_ratio_opt = elastic_cv.l1_ratio_

# Mostrar resultados
print(f"Alpha óptimo encontrado por ElasticNetCV: {alpha_opt:.5f}")
print(f"L1_ratio óptimo encontrado por ElasticNetCV: {l1_ratio_opt:.2f}")
print(f"Tiempo de entrenamiento (ElasticNetCV): {tiempo_cv:.4f} segundos")

# === refinamiento alrededor del óptimo ===

# Definimos una grilla centrada en los mejores valores encontrados
param_grid_elastic = {
    "alpha": np.linspace(alpha_opt * 0.5, alpha_opt * 1.5, 10),
    "l1_ratio": np.linspace(
        max(0.1, l1_ratio_opt - 0.3),
        min(1.0, l1_ratio_opt + 0.3),
        10
    )
}

# GridSearchCV con validación cruzada consistente
grid_elastic = GridSearchCV(
    estimator=ElasticNet(max_iter=10000, random_state=42),
    param_grid=param_grid_elastic,
    scoring="neg_mean_squared_error",
    cv=cv,
    n_jobs=-1
)

# Ajuste con la variable transformada
grid_elastic.fit(X_train_scaled, np.log1p(y_train))

# Guardamos el mejor modelo encontrado
modelo_elastic = grid_elastic.best_estimator_

# Mostrar hiperparámetros óptimos refinados
print("Mejores hiperparámetros encontrados por GridSearchCV:")
print(f"  alpha     : {grid_elastic.best_params_['alpha']:.5f}")
print(f"  l1_ratio  : {grid_elastic.best_params_['l1_ratio']:.2f}")


# === mapa de calor de sensibilidad de MSE ===

# Convertir resultados del GridSearchCV a DataFrame
df_grid = pd.DataFrame(grid_elastic.cv_results_)

# Extraer alpha y l1_ratio
df_grid["alpha"] = df_grid["params"].apply(lambda d: d["alpha"])
df_grid["l1_ratio"] = df_grid["params"].apply(lambda d: d["l1_ratio"])
df_grid["MSE"] = -df_grid["mean_test_score"]

# Redondear para mejor visualización
df_grid["alpha_round"] = df_grid["alpha"].round(4)
df_grid["l1_ratio_round"] = df_grid["l1_ratio"].round(2)

# Crear tabla pivote para el heatmap
pivot_table = df_grid.pivot(index="l1_ratio_round", columns="alpha_round", values="MSE")

# Graficar heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(
    pivot_table,
    annot=True,
    fmt=".2g",
    cmap="viridis",
    linewidths=0.3,
    cbar_kws={'label': 'MSE'},
    annot_kws={"size": 8}
)

plt.title("Sensibilidad del MSE a los hiperparámetros - ElasticNet", fontsize=14)
plt.xlabel("Alpha", fontsize=12)
plt.ylabel("L1 Ratio", fontsize=12)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()

# Guardar imagen
os.makedirs("figuras", exist_ok=True)
plt.savefig("figuras/sensibilidad_elasticnet_heatmap.png", dpi=300)
plt.show()


# Separar la fila 'Promedio' del resto
df_elastic_folds = df_elastic_cv[df_elastic_cv["Fold"] != "Promedio"].copy()
df_elastic_avg = df_elastic_cv[df_elastic_cv["Fold"] == "Promedio"].copy()

# Convertir columnas numéricas a formato adecuado
styled_folds = df_elastic_folds.style.format({
    "MAE": "{:,.2f}",
    "MSE": "{:,.2e}",
    "R2": "{:.4f}",
    "MAPE": "{:.2f}"
}).highlight_max(axis=0, color="lightgreen").highlight_min(axis=0, color="lightcoral")

# Mostrar resultados por fold
print("Resultados de validación cruzada – ElasticNet (por fold):")
display(styled_folds)

# Mostrar fila de promedio aparte
print("\nPromedio de métricas:")
display(df_elastic_avg.style.format({
    "MAE": "{:,.2f}",
    "MSE": "{:,.2e}",
    "R2": "{:.4f}",
    "MAPE": "{:.2f}"
}))


# === Entrenamiento final con todo el conjunto de entrenamiento ===
start = time.time()
modelo_elastic.fit(X_train_scaled, np.log1p(y_train))
end = time.time()
tiempo_entrenamiento_final = end - start

# === Predicción y destransformación ===
y_pred_log_test = modelo_elastic.predict(X_test_scaled)
y_pred_test = np.expm1(y_pred_log_test)  # Volver a escala original

# === Cálculo de métricas en escala original ===
mae_test = mean_absolute_error(y_test, y_pred_test)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_test = np.sqrt(mse_test)
r2_test = r2_score(y_test, y_pred_test)
mape_test, n_obs_test = calcular_mape_seguro(y_test, y_pred_test)

# Normalizar errores
mae_norm_test, rmse_norm_test = normalizar_metricas(mae_test, rmse_test, y_test)

# === Mostrar resultados formateados ===
print("Desempeño final del modelo ElasticNet (conjunto de test):")
print(f"MAE   = {mae_test:,.2f}  ({mae_norm_test:.2f}% del valor promedio)")
print(f"MSE   = {mse_test:.2e}")
print(f"RMSE  = {rmse_test:,.2f}  ({rmse_norm_test:.2f}% del valor promedio)")
print(f"R²    = {r2_test:.4f}")
print(f"MAPE  = {mape_test:.2f}% (calculado sobre {n_obs_test} observaciones)")
print(f"Tiempo de entrenamiento final: {tiempo_entrenamiento_final:.4f} segundos")

# === Calcular residuos en escala original ===
residuos = y_test - y_pred_test

# Estadísticas básicas
media_residuos = np.mean(residuos)
std_residuos = np.std(residuos)

print(f"Media de los residuos: {media_residuos:.2f}")
print(f"Desviación estándar: {std_residuos:.2f}")


# === Gráfico de residuos vs predicción ===
plt.figure(figsize=(8, 5))
plt.scatter(y_pred_test, residuos, alpha=0.5, edgecolors='k')
plt.axhline(0, color='red', linestyle='--', linewidth=1.5)
plt.xlabel("Valores predichos")
plt.ylabel("Residuos")
plt.title("Residuos vs Predicciones – ElasticNet")
plt.grid(True, linestyle='--', alpha=0.3)
plt.tight_layout()
plt.savefig("figuras/residuos_vs_pred_elasticnet.png", dpi=300)
plt.show()


# === Histograma de residuos ===
plt.figure(figsize=(8, 5))
sns.histplot(residuos, kde=True, bins=30, color='skyblue')
plt.title("Histograma de residuos – ElasticNet")
plt.xlabel("Residuos")
plt.ylabel("Frecuencia")
plt.tight_layout()
plt.savefig("figuras/histograma_residuos_elasticnet.png", dpi=300)
plt.show()

# ===  QQ-plot para evaluar normalidad ===
plt.figure(figsize=(8, 6))
ax = plt.gca()
stats.probplot(residuos, dist="norm", plot=ax)

# Estética y etiquetas
ax.set_title("Gráfico QQ de residuos – Evaluación de normalidad (ElasticNet)", fontsize=13)
ax.set_xlabel("Cuantiles teóricos")
ax.set_ylabel("Cuantiles de los residuos")
ax.grid(True, linestyle='--', alpha=0.4)

# Guardar gráfico
os.makedirs("figuras", exist_ok=True)
plt.tight_layout()
plt.savefig("figuras/qqplot_residuos_elasticnet_refinado.png", dpi=300)
plt.show()

# === Subpaso 6.5: Prueba de Shapiro-Wilk ===
from scipy.stats import shapiro

stat, p_value = shapiro(residuos)
print(f"Shapiro-Wilk: estadístico = {stat:.4f}, p-valor = {p_value:.4f}")

if p_value > 0.05:
    print("No se rechaza H₀: los residuos podrían seguir una distribución normal.")
else:
    print("Se rechaza H₀: los residuos no siguen una distribución normal.")

print("")

# === Subpaso 6.6: Estadístico de Durbin-Watson ===
from statsmodels.stats.stattools import durbin_watson

dw = durbin_watson(residuos)
print(f"Durbin-Watson: {dw:.4f}")

if 1.5 < dw < 2.5:
    print("No hay evidencia fuerte de autocorrelación.")
else:
    print("Posible autocorrelación: revisar más a fondo.")


# === Análisis de colinealidad con VIF (ElasticNet) ===

# Cargar nombres reales desde archivo .pkl
try:
    columnas = joblib.load("data/nombres_columnas.pkl")
except FileNotFoundError:
    raise FileNotFoundError("No se encontró el archivo 'data/nombres_columnas.pkl'. Ejecuta el bloque de exportación en el notebook de preprocesamiento.")

#  Asignar nombres al DataFrame escalado
X_scaled_df = pd.DataFrame(X_train_scaled, columns=columnas)

#  Agregar constante y calcular VIF
X_scaled_vif = add_constant(X_scaled_df)

vif_elastic = pd.DataFrame()
vif_elastic["Variable"] = X_scaled_vif.columns
vif_elastic["VIF"] = [
    variance_inflation_factor(X_scaled_vif.values, i) for i in range(X_scaled_vif.shape[1])
]

# Limpiar, ordenar y guardar
vif_elastic = vif_elastic[vif_elastic["Variable"] != "const"].reset_index(drop=True)
vif_elastic = vif_elastic.sort_values(by="VIF", ascending=False)

# Guardar CSV
os.makedirs("data", exist_ok=True)
vif_elastic.to_csv("data/vif_elasticnet.csv", index=False)

# Mostrar Top 10
print("Top 10 variables con mayor VIF (ElasticNet):")
display(vif_elastic.head(10))


# === Cargar DataFrame de VIF ===
vif_elastic = pd.read_csv("data/vif_elasticnet.csv")

# === Filtro y ordenamiento ===
vif_altos = vif_elastic[vif_elastic["VIF"] > 5].copy()
vif_altos = vif_altos.sort_values(by="VIF", ascending=False).head(30)

# === Clasificación visual por gravedad ===
def clasificar_vif(v):
    if np.isinf(v):
        return "Infinito"
    elif v > 10:
        return "Crítico (>10)"
    else:
        return "Moderado (5–10)"

vif_altos["Categoría"] = vif_altos["VIF"].apply(clasificar_vif)
vif_altos["Etiqueta"] = vif_altos["VIF"].apply(lambda x: "∞" if np.isinf(x) else f"{x:.1f}")

# === Paleta por categoría ===
palette = {
    "Moderado (5–10)": "#F9C74F",  # amarillo
    "Crítico (>10)": "#F94144",   # rojo
    "Infinito": "#6A0572"         # púrpura oscuro
}

# === Crear gráfico ===
plt.figure(figsize=(12, 9))
ax = sns.barplot(
    data=vif_altos,
    x="VIF",
    y="Variable",
    hue="Categoría",
    dodge=False,
    palette=palette
)

# === Líneas de referencia ===
plt.axvline(5, color='gray', linestyle='--', linewidth=1, label='Umbral moderado (5)')
plt.axvline(10, color='black', linestyle='--', linewidth=1.2, label='Umbral crítico (10)')

# === Etiquetas numéricas sobre las barras ===
for i, (v, txt) in enumerate(zip(vif_altos["VIF"], vif_altos["Etiqueta"])):
    x_pos = 1000 if np.isinf(v) else min(v + 5, 980)
    ax.text(x_pos, i, txt, va='center', ha='left', fontsize=9, color='black')

# === Estética ===
plt.xlim(0, 1050)
plt.title("Top 30 variables con mayor VIF", fontsize=15)
plt.xlabel("Factor de Inflación de la Varianza (VIF)")
plt.ylabel("Variable")
plt.legend(loc="lower right", frameon=True)
plt.grid(True, axis='x', linestyle='--', alpha=0.3)
plt.tight_layout()

# === Guardado seguro ===
os.makedirs("figuras", exist_ok=True)
plt.savefig("figuras/vif_top30_elasticnet_refinado.png", dpi=300)
plt.show()


# ===  Cargar nombres reales de las variables ===
columnas = joblib.load("data/nombres_columnas.pkl")

# === Obtener coeficientes del modelo entrenado ===
coef_elastic = modelo_elastic.coef_

# Validación
assert len(coef_elastic) == len(columnas), "El número de coeficientes no coincide con el número de variables."

# === 3. Crear DataFrame de coeficientes ===
df_coef_elastic = pd.DataFrame({
    "Variable": columnas,
    "Coeficiente": coef_elastic
})

# Guardar para análisis posterior
os.makedirs("data", exist_ok=True)
df_coef_elastic.to_csv("data/coeficientes_elasticnet.csv", index=False)

# === 4. Agregar columna de importancia (valor absoluto) y filtrar Top 20 ===
df_coef_elastic["Importancia"] = df_coef_elastic["Coeficiente"].abs()
top20 = df_coef_elastic.sort_values(by="Importancia", ascending=False).head(20)

# Ordenar para mejor visualización
top20 = top20.sort_values("Coeficiente")

# === 5. Visualización del Top 20 ===
plt.figure(figsize=(10, 8))
sns.barplot(data=top20, x="Coeficiente", y="Variable", palette="coolwarm", dodge=False)
plt.axvline(0, color='black', linestyle='--', linewidth=1)
plt.title("Top 20 coeficientes más importantes – ElasticNet", fontsize=14)
plt.xlabel("Valor del coeficiente")
plt.ylabel("Variable")
plt.grid(True, linestyle='--', alpha=0.3, axis='x')
plt.tight_layout()

# === 6. Guardar figura ===
os.makedirs("figuras", exist_ok=True)
plt.savefig("figuras/top20_coeficientes_elasticnet.png", dpi=300)
plt.show()


# === Exportación de predicciones en test y métricas (coherente con log) ===

# Realizar predicciones (escala logarítmica) y reconvertir a escala original
y_test_pred_log = modelo_elastic_final.predict(X_test_scaled)
y_test_pred = np.expm1(y_test_pred_log)  # Transformación inversa

# Crear DataFrame de comparación
df_pred_elastic = pd.DataFrame({
    "Actual": y_test,
    "Predicho": y_test_pred
})
df_pred_elastic["Error Absoluto"] = np.abs(df_pred_elastic["Actual"] - df_pred_elastic["Predicho"])
df_pred_elastic["Error Relativo (%)"] = 100 * df_pred_elastic["Error Absoluto"] / df_pred_elastic["Actual"]

# Guardar predicciones
os.makedirs("data", exist_ok=True)
df_pred_elastic.to_csv("data/predicciones_test_elasticnet.csv", index=False)

# Calcular y exportar métricas en escala original
mae = mean_absolute_error(y_test, y_test_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
r2 = r2_score(y_test, y_test_pred)
mape, n_obs = calcular_mape_seguro(y_test, y_test_pred)
mae_norm, rmse_norm = normalizar_metricas(mae, rmse, y_test)

df_metrics_elastic = pd.DataFrame({
    "Modelo": ["ElasticNet"],
    "MAE": [mae],
    "RMSE": [rmse],
    "R2": [r2],
    "MAPE (%)": [mape],
    "MAE normalizado (%)": [mae_norm],
    "RMSE normalizado (%)": [rmse_norm],
    "Observaciones MAPE": [n_obs]
})

df_metrics_elastic.to_csv("data/metricas_test_elasticnet.csv", index=False)

# Vista previa
pd.set_option('display.max_rows', 100)
df_pred_elastic.sample(10)


# === Valores predichos vs reales ===
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_test_pred, alpha=0.6, edgecolors='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel("Valor real")
plt.ylabel("Valor predicho")
plt.title("Predicciones vs Valores reales – ElasticNet")
plt.grid(True, linestyle='--', alpha=0.4)
plt.tight_layout()
plt.savefig("figuras/predicho_vs_real_elasticnet.png", dpi=300)
plt.show()
