import streamlit as st
import pandas as pd
from pathlib import Path
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go

# ==== CONFIGURACI√ìN GENERAL ====
st.set_page_config(page_title="Comparativa de Modelos TAM 2025-1", layout="wide")

# ==== ESTILO PERSONALIZADO (CSS) ====
st.markdown("""
    <style>
    html, body, [class*="css"]  {
        font-family: 'Segoe UI', sans-serif;
        font-size: 16px;
        color: #1f2937;
    }
    h1 {
        font-size: 2.5rem;
        font-weight: bold;
        color: #0d6efd;
    }
    h2, h3 {
        color: #1a1a1a;
    }
    section[data-testid="stSidebar"] {
        background-color: #20232a;
        color: #ffffff;
    }
    .stRadio label {
        font-size: 16px;
        color: #ffffff;
    }
    .dataframe thead tr th {
        background-color: #f1f1f1;
        color: #333;
    }
    .dataframe tbody tr td {
        background-color: #fafafa;
        color: #111;
    }
    </style>
""", unsafe_allow_html=True)

# ==== RUTAS BASE ====
root_path = Path(__file__).resolve().parent.parent
data_path = root_path / "data"
image_path = Path("C:/Users/PC/Downloads/imagen.jpg")

# ==== ENCABEZADO ====
st.title("Dashboard de Evaluaci√≥n de Modelos - TAM 2025-1")
st.markdown("""
Bienvenido al panel interactivo de evaluaci√≥n y comparaci√≥n de modelos de regresi√≥n aplicados al conjunto de datos **Ames Housing**.  
Aqu√≠ podr√°s visualizar m√©tricas clave, distribuciones de errores, gr√°ficos de predicci√≥n y mucho m√°s para cada modelo entrenado.

Este tablero busca facilitar la **selecci√≥n informada** de los **3 mejores modelos**, con base en criterios estad√≠sticos y visuales.
""")

# ==== SIDEBAR ====
st.sidebar.title("üîé Navegaci√≥n")
opcion = st.sidebar.radio(
    "Selecciona una secci√≥n",
    ["Introducci√≥n", 
     "Comparativa de m√©tricas", 
     "Predicciones vs. Reales",
     "Curvas de aprendizaje",
     "Conclusi√≥n"]
)

# ==== INTRODUCCI√ìN ====
if opcion == "Introducci√≥n":
    st.subheader("üìò Bienvenida al Dashboard Interactivo")

    st.image(image_path, use_container_width=True)

    st.markdown("""
    Este tablero interactivo te permite explorar, comparar e interpretar el rendimiento de distintos modelos de **regresi√≥n** aplicados al conjunto de datos **Ames Housing** ‚Äî un registro detallado de propiedades residenciales que incluye m√°s de 70 caracter√≠sticas por casa.

    ### üéØ ¬øQu√© busca responder este dashboard?
    - ¬øQu√© modelo predice mejor el **precio de una vivienda**?
    - ¬øCu√°l es m√°s **estable** (menos variable)?
    - ¬øC√≥mo se comportan frente a **nuevos datos**?

    ### üìè ¬øQu√© m√©tricas se utilizan?
    Cada modelo se evalu√≥ con las siguientes medidas:

    | M√©trica | Qu√© mide | Interpretaci√≥n |
    |--------|----------|----------------|
    | `MAE` (Error Absoluto Medio) | Promedio del error absoluto | M√°s bajo es mejor |
    | `RMSE` (Ra√≠z del Error Cuadr√°tico Medio) | Penaliza errores grandes | M√°s bajo es mejor |
    | `R¬≤` (Coeficiente de determinaci√≥n) | Qu√© tanto explica el modelo la variabilidad | Se espera cercano a 1 |
    | `MAPE` (%) | Error medio porcentual | Indica error relativo al valor real |

    Las unidades de `MAE` y `RMSE` est√°n expresadas en **d√≥lares estadounidenses (USD)**.  
    El `MAPE` est√° expresado como **porcentaje de error promedio**.

    ---

    ### üëÄ ¬øQu√© puedes hacer aqu√≠?
    - Visualizar gr√°ficas de desempe√±o por modelo.
    - Comparar resultados estad√≠sticos.
    - Ver predicciones vs. valores reales.
    - Evaluar consistencia mediante curvas de aprendizaje.
    
    ---
    **Este tablero est√° dise√±ado para ayudarte a tomar decisiones informadas** sobre qu√© modelo aplicar, ajustar o desplegar.  
    No necesitas ser experto en Machine Learning para interpretarlo üòä.
    """)




# ==== COMPARATIVA DE M√âTRICAS ====
elif opcion == "Comparativa de m√©tricas":
    st.subheader("üìä Comparaci√≥n de m√©tricas por modelo")

    resumen_path = data_path / "resumen_mejores_modelos.csv"

    # Leer correctamente la segunda fila como encabezado
    resumen_df = pd.read_csv(resumen_path, header=[1], index_col=0)

    # Renombrar columnas para que tengan formato m√©trica_estad√≠stica
    resumen_df.columns = [
        'MAE_mean', 'MAE_std',
        'RMSE_mean', 'RMSE_std',
        'R2_mean', 'R2_std',
        'MAPE_mean', 'MAPE_std'
    ]

    # Convertir a formato largo
    resumen_long = resumen_df.stack().reset_index()
    resumen_long.columns = ['Modelo', 'Metrica_Completa', 'Valor']
    resumen_long[['M√©trica', 'Estad√≠stica']] = resumen_long['Metrica_Completa'].str.split('_', expand=True)

    # Pivot a formato ancho con columnas mean y std
    resumen_pivot = resumen_long.pivot(index=['Modelo', 'M√©trica'], columns='Estad√≠stica', values='Valor').reset_index()

    # Gr√°ficos para cada m√©trica
    for metrica in ['MAE', 'RMSE', 'MAPE', 'R2']:
        metrica_df = resumen_pivot[resumen_pivot['M√©trica'] == metrica]
        fig = px.bar(
            metrica_df,
            x='Modelo',
            y='mean',
            error_y='std',
            color='Modelo',
            text='mean',
            title=f'{metrica} (media ¬± std)',
            color_discrete_sequence=px.colors.qualitative.Vivid
        )
        fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig.update_layout(
            yaxis_title=metrica,
            xaxis_title="Modelo",
            showlegend=False,
            bargap=0.3,
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)

    # Tabla estilizada
    st.subheader("üìã Tabla resumen de m√©tricas")
    st.dataframe(
        resumen_df.style.format("{:.3f}").highlight_max(axis=0, color="lightgreen"),
        use_container_width=True
    )

    # === Comentario resumen final ===
    st.markdown("---")
    st.markdown("### üìå Observaciones clave sobre las m√©tricas:")

    st.markdown("""
    - Los modelos evaluados muestran diferencias relevantes en las m√©tricas de desempe√±o.
     **BayesianRidge** y **GaussianProcess** destacan por su **bajo MAE y MAPE**, lo que indica alta precisi√≥n en las predicciones.
    - **KernelRidge** mantiene un buen equilibrio entre error medio y estabilidad (baja desviaci√≥n est√°ndar).
    - Las barras de error revelan que algunos modelos tienen **rendimientos m√°s consistentes** que otros.
    - La m√©trica **R¬≤** refuerza el buen ajuste global de los modelos principales.

    > ‚úÖ Estos resultados sugieren que **BayesianRidge** y **GaussianProcess** son opciones s√≥lidas por su rendimiento promedio y estabilidad.
    """)



# ==== PREDICCIONES VS. REALES ====
elif opcion == "Predicciones vs. Reales":
    st.subheader("üìà Comparaci√≥n: Predicciones vs. Valores reales")
    st.markdown("""
    Observa a continuaci√≥n c√≥mo se comparan las predicciones frente a los valores reales para los **3 mejores modelos**.
    Cada gr√°fico incluye una l√≠nea de referencia perfecta (_Y = X_) para evaluar visualmente la calidad de las predicciones.
    """)

    # Diccionario con los archivos de predicci√≥n
    pred_files = {
        "GaussianProcess": "predicciones_test_gaussian.csv",
        "BayesianRidge": "predicciones_test_bayesianridge.csv",
        "KernelRidge": "predicciones_test_kernelridge.csv"
    }

    # Columnas esperadas en los CSV
    expected_cols = {'Actual', 'Predicho'}

    for model, file_name in pred_files.items():
        file_path = data_path / file_name

        st.markdown(f"---\n### üîπ {model}")

        if not file_path.exists():
            st.error(f"‚ùå Archivo no encontrado: `{file_name}`")
            continue

        try:
            df_pred = pd.read_csv(file_path)

            if not expected_cols.issubset(df_pred.columns):
                st.warning("‚ö†Ô∏è El archivo no contiene las columnas esperadas: `Actual` y `Predicho`")
                st.dataframe(df_pred.head())  # Mostrar preview si tiene otras columnas
                continue

            # Calcular errores para resumen (opcional)
            df_pred['Error'] = df_pred['Actual'] - df_pred['Predicho']

            # Gr√°fico Real vs Predicho
            fig = go.Figure()

            fig.add_trace(go.Scatter(
                x=df_pred['Actual'],
                y=df_pred['Predicho'],
                mode='markers',
                marker=dict(color='dodgerblue', opacity=0.6, size=6),
                name='Predicciones'
            ))

            fig.add_trace(go.Scatter(
                x=df_pred['Actual'],
                y=df_pred['Actual'],
                mode='lines',
                line=dict(color='crimson', dash='dash'),
                name='L√≠nea ideal'
            ))

            fig.update_layout(
                title=f"{model}: Valor Real vs. Predicci√≥n",
                xaxis_title="Valor real",
                yaxis_title="Predicci√≥n",
                height=450,
                margin=dict(l=40, r=40, t=60, b=40)
            )

            st.plotly_chart(fig, use_container_width=True)

            # Estad√≠sticas b√°sicas del error
            st.caption("üìå Estad√≠sticas de error:")
            col1, col2, col3 = st.columns(3)
            col1.metric("MAE", f"{abs(df_pred['Error']).mean():,.2f}")
            col2.metric("RMSE", f"{(df_pred['Error']**2).mean()**0.5:,.2f}")
            col3.metric("R¬≤", f"{df_pred[['Actual', 'Predicho']].corr().iloc[0,1]**2:.3f}")

        except Exception as e:
            st.error(f"‚ùå Error procesando el archivo `{file_name}`: {str(e)}")
    # === Comentario resumen final ===
    st.markdown("---")
    st.markdown("### üß† Observaciones finales:")

    st.markdown("""
    - Un modelo ideal tendr√≠a sus puntos alineados perfectamente sobre la l√≠nea roja (`Y = X`).
    - **GaussianProcess** y **BayesianRidge** muestran buena concentraci√≥n alrededor de la l√≠nea ideal.
    - **KernelRidge** tambi√©n presenta un desempe√±o competitivo, aunque con ligeros errores para valores extremos.
    - Las m√©tricas presentadas (MAE, RMSE, R¬≤) refuerzan la calidad general de estos modelos.

    > üí° Esta visualizaci√≥n es clave para evaluar **precisi√≥n individual por instancia**, no solo promedios agregados.
    """)







# ==== CURVAS DE APRENDIZAJE ====
elif opcion == "Curvas de aprendizaje":
    st.subheader("üìà Curvas de Aprendizaje por Modelo")

    st.markdown("""
    Las **curvas de aprendizaje** muestran c√≥mo evoluciona el desempe√±o del modelo a medida que aumentan las muestras de entrenamiento.  
    Ayudan a identificar posibles problemas de *underfitting* (modelo muy simple) o *overfitting* (modelo demasiado ajustado).

    **Interpretaci√≥n esperada:**
    - üü¢ **Underfitting:** Las curvas se mantienen bajas ‚Üí no aprende suficiente.
    - üü† **Overfitting:** La curva de entrenamiento es alta, pero la de validaci√≥n no.
    - ‚úÖ **Buen aprendizaje:** Ambas curvas convergen con valores altos.

    **M√©trica utilizada:** Error cuadr√°tico medio (MSE) en escala log-transformada.
    """)

    curve_images = {
        "GaussianProcess": "curva_aprendizaje_gpr.png",
        "BayesianRidge": "curva_aprendizaje_bayesianridge.png",
        "KernelRidge": "curva_aprendizaje_kernelridge.png"
    }

    for model, file_name in curve_images.items():
        image_path = data_path / file_name

        if image_path.exists():
            st.markdown(f"### üîπ {model}")
            st.image(image_path, use_container_width=True, caption=f"Curva de aprendizaje ‚Äì {model}")
            st.caption(f"üìä Observa el equilibrio entre aprendizaje y generalizaci√≥n del modelo **{model}** a medida que aumenta el tama√±o del set de entrenamiento.")
        else:
            st.warning(f"‚ö†Ô∏è No se encontr√≥ la imagen: `{file_name}` para el modelo {model}")




# ==== CONCLUSI√ìN ====
elif opcion == "Conclusi√≥n":
    st.subheader("Conclusi√≥n final")

    st.markdown("""
    ### üß† Hallazgos clave del an√°lisis:

    - Se evaluaron diversos modelos de regresi√≥n, incluyendo **Bayesian Ridge**, **Gaussian Process Regressor (GPR)** y **Kernel Ridge**.
    - A trav√©s de **curvas de aprendizaje**, se observ√≥ c√≥mo cada modelo generaliza con distintas cantidades de datos de entrenamiento:
        - El modelo **Bayesian Ridge** mostr√≥ un comportamiento estable y generalizaci√≥n progresiva, con errores de validaci√≥n decrecientes al aumentar los datos.
        - El **GPR**, aunque m√°s costoso computacionalmente, logr√≥ errores de validaci√≥n bajos, especialmente √∫til en datasets de tama√±o moderado.
        - El an√°lisis de sensibilidad con **Kernel Ridge** revel√≥ que la elecci√≥n de hiperpar√°metros como `alpha` y `gamma` tiene un impacto considerable sobre el rendimiento, visualizado mediante mapas de calor.

    ### ‚úÖ Recomendaciones generales:

    - Si se prioriza interpretabilidad y eficiencia, **Bayesian Ridge** es una excelente elecci√≥n.
    - Para tareas donde se requiera mayor flexibilidad y se cuente con capacidad de c√≥mputo, **GPR** puede ofrecer mejor precisi√≥n.
    - Se recomienda realizar b√∫squeda bayesiana o mapas de calor como apoyo visual para elegir hiperpar√°metros en modelos sensibles como **Kernel Ridge**.

    ### üìå Sugerencia final:

    - Considerar el **trade-off entre complejidad, precisi√≥n y coste computacional** al seleccionar el modelo ideal.
    - Para futuras mejoras, se podr√≠a aplicar **selecci√≥n de caracter√≠sticas**, **ingenier√≠a de atributos**, y comparar con modelos no lineales como **XGBoost** o **Redes Neuronales**.

    """)

    st.success("La combinaci√≥n de an√°lisis visual, ajuste de hiperpar√°metros y evaluaci√≥n sistem√°tica permiti√≥ identificar modelos robustos y adecuados para este conjunto de datos.")


